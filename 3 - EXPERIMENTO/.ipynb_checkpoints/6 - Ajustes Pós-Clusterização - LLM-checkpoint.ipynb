{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dac3965-fada-4b3d-b9bd-cba287ddf00f",
   "metadata": {},
   "source": [
    "# üìä An√°lise, Sumariza√ß√£o e Reclassifica√ß√£o de t√≥picos (Clusters) com LLM\n",
    "\n",
    "Este script tem como objetivo principal a **an√°lise, sumariza√ß√£o e reclassifica√ß√£o de t√≥picos (clusters)** associados a processos judiciais envolvendo MEI, utilizando modelos de linguagem (LLMs). A seguir, as principais etapas executadas:\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Sumariza√ß√£o dos Clusters\n",
    "\n",
    "- S√£o selecionados os **20 processos mais pr√≥ximos do centr√≥ide** de cada t√≥pico identificado.\n",
    "- Para cada t√≥pico (ou cluster), o LLM gera **5 informa√ß√µes-chave** com base nos textos:\n",
    "  - `descricao_caso`\n",
    "  - `questoes_em_discussao`\n",
    "  - `solucoes_propostas`\n",
    "  - `tese_juridica`\n",
    "- O modelo responde com os seguintes resumos, que s√£o armazenados no banco de dados:\n",
    "  - `descricao_curta_cluster`\n",
    "  - `descricao_longa_cluster`\n",
    "  - `questoes_discussao_cluster`\n",
    "  - `solucoes_propostas_cluster`\n",
    "  - `teses_cluster`\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Agrupamento de T√≥picos Menores\n",
    "\n",
    "- S√£o identificados os **30 t√≥picos com maior n√∫mero de registros**.\n",
    "- Os t√≥picos restantes (menores) s√£o comparados com os principais:\n",
    "  - Para cada t√≥pico menor, o LLM verifica se ele pode ser **agrupado a um dos 30 maiores**, usando como refer√™ncia suas descri√ß√µes.\n",
    "  - Caso seja poss√≠vel, os registros s√£o reclassificados para o t√≥pico mais adequado.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Repescagem dos Processos \"Noise\"\n",
    "\n",
    "- Um prompt espec√≠fico √© definido na fun√ß√£o `verificar_classificacao`.\n",
    "- O script seleciona todos os **t√≥picos j√° existentes** (com coordenadas UMAP).\n",
    "- Em seguida, seleciona todos os **processos que n√£o possuem n√∫mero de t√≥pico atribu√≠do** (`noise`).\n",
    "- Para cada processo \"noise\", o LLM avalia se ele pode ser inclu√≠do em algum dos t√≥picos existentes:\n",
    "  - Se sim, os campos do processo s√£o atualizados com as informa√ß√µes do t√≥pico correspondente.\n",
    "\n",
    "---\n",
    "\n",
    "## üìç Visualiza√ß√£o dos Clusters (Gr√°fico de Bolhas)\n",
    "\n",
    "- S√£o selecionados os campos:\n",
    "  - `descricao_caso`, `questoes_em_discussao`, `coordenadas_umap`, `numero_topico_bertopic_padrao`\n",
    "- Esses dados s√£o enviados √† fun√ß√£o `visualizar_grafico_cluster`, que:\n",
    "  - Plota cada processo no espa√ßo 2D (reduzido por UMAP).\n",
    "  - Agrupa visualmente os processos do mesmo t√≥pico com:\n",
    "    - **Mesma cor**\n",
    "    - **C√≠rculo ao redor**\n",
    "    - **Raio proporcional √† quantidade de registros**\n",
    "    - **Centro do c√≠rculo localizado no centr√≥ide do cluster**\n",
    "  - Exibe **legenda com percentual de processos por t√≥pico**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5a25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import warnings\n",
    "from datetime import datetime, date\n",
    "from collections import Counter\n",
    "from psycopg2.extras import execute_values\n",
    "from typing import Optional\n",
    "import requests\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Circle\n",
    "from adjustText import adjust_text\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from IPython.display import display, clear_output\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*pandas only supports SQLAlchemy.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b44a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conex√£o\n",
    "def get_connection():\n",
    "    return psycopg2.connect(\n",
    "        dbname=\"PROCESSOS\",\n",
    "        user=\"\",\n",
    "        password=\"\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29744a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vari√°veis globais para armazenar o token e o hor√°rio em que foi gerado\n",
    "token = None\n",
    "last_token_time = 0\n",
    "\n",
    "# Fun√ß√£o para obter o token da API\n",
    "def get_token():\n",
    "    client_id = ''\n",
    "    client_secret = ''\n",
    "    result = requests.request('POST', \n",
    "        \"...\", \n",
    "        data={\"grant_type\":\"client_credentials\"}, \n",
    "        auth=(client_id, client_secret))\n",
    "\n",
    "    if result.ok:\n",
    "        return result.json()['access_token']\n",
    "    else:\n",
    "        raise Exception(\"Erro ao obter o token\")\n",
    "\n",
    "# Fun√ß√£o para verificar se o token est√° expirado (renova se necess√°rio)\n",
    "def get_valid_token():\n",
    "    global token, last_token_time\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Se o token n√£o existe ou j√° passaram mais de 20 minutos, obtemos um novo\n",
    "    if token is None or (current_time - last_token_time) > 20 * 60:  # 20 minutos em segundos\n",
    "        token = get_token()\n",
    "        last_token_time = current_time\n",
    "        print(\"Novo token obtido.\")\n",
    "\n",
    "    return token\n",
    "\n",
    "# Fun√ß√£o para invocar o LLM\n",
    "def invoke(prompt, modelo,token, temperature=0, max_tokens=10000, stream=False):\n",
    "    # Obt√©m o token v√°lido (renova se necess√°rio)\n",
    "    \n",
    "\n",
    "    payload_data = {\n",
    "        \"model\": modelo,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stream\": stream\n",
    "    }\n",
    "\n",
    "    result = requests.request(\"POST\", \n",
    "        '...', \n",
    "\n",
    "        data=json.dumps(payload_data), \n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {token}\", \n",
    "            \"Content-Type\":\"application/json\"})\n",
    "\n",
    "    if result.ok:\n",
    "        res = result.json()\n",
    "        resposta = res[\"choices\"][0][\"message\"]['content']\n",
    "        return resposta\n",
    "    else:\n",
    "        print(result.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cffec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_e_salvar_clusters(modelo, token):\n",
    "    conn = get_connection()\n",
    "    cur = conn.cursor()\n",
    "    modelo = 'pixtral-12b'\n",
    "\n",
    "    # =========================\n",
    "    # 0) Limpar campos antigos antes de atualizar\n",
    "    # =========================\n",
    "    print(\"üßπ Limpando campos anteriores dos clusters...\")\n",
    "    cur.execute(\"\"\"\n",
    "        UPDATE processos SET\n",
    "            descricao_curta_cluster = NULL,\n",
    "            descricao_longa_cluster = NULL,\n",
    "            questoes_discussao_cluster = NULL,\n",
    "            solucoes_propostas_cluster = NULL,\n",
    "            teses_cluster = NULL\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Campos limpos com sucesso.\\n\")\n",
    "\n",
    "    df = pd.read_sql_query(\"\"\"\n",
    "        SELECT id, numero_processo_tribunal, descricao_caso, questoes_em_discussao, \n",
    "               solucoes_propostas, tese, numero_topico_llm, descricao_topico_llm, \n",
    "               proximo_do_centroid\n",
    "        FROM processos \n",
    "        WHERE proximo_do_centroid = 1\n",
    "    \"\"\", conn)\n",
    "\n",
    "    grupos = df.groupby(\"descricao_topico_llm\")\n",
    "\n",
    "    for topico, grupo in grupos:\n",
    "        casos = \"\\n\\n\".join(grupo['descricao_caso'].dropna())\n",
    "\n",
    "        questoes = \"\\n\\n\".join(grupo['questoes_em_discussao'].dropna())\n",
    "        solucoes = \"\\n\\n\".join(grupo['solucoes_propostas'].dropna())\n",
    "        teses = \"\\n\\n\".join(grupo['tese'].dropna())\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"\\n\\n===========================\")\n",
    "        print(f\"üîé T√≥pico {topico} - {grupo['descricao_topico_llm'].iloc[0]}\")\n",
    "        print(f\"IDs: {grupo['id'].tolist()}\")\n",
    "\n",
    "        # 1. Descri√ß√£o curta\n",
    "        prompt_1 = \"Voc√™ √© um assistente jur√≠dico. Com base nas descri√ß√µes dos casos abaixo, escreva um resumo curto (1 par√°grafo com at√© 150 caracteres) que represente o tema central em comum nos processos judiciais listados:\\n\\n\" + casos\n",
    "        texto_1 = invoke(prompt_1, modelo, token)\n",
    "        print(\"\\nüìå Descri√ß√£o curta:\")\n",
    "        print(texto_1)\n",
    "\n",
    "        # 2. Descri√ß√£o longa\n",
    "        #prompt_2 = \"Voc√™ √© um assistente jur√≠dico. Com base nas descri√ß√µes dos casos abaixo, escreva um texto descritivo em at√© 500 caracteres sobre o tema comum desses processos:\\n\\n\" + casos\n",
    "        #texto_2 = invoke(prompt_2, modelo, token)\n",
    "        #print(\"\\nüìò Descri√ß√£o longa:\")\n",
    "        #print(texto_2)\n",
    "        texto_2 = \"\"\n",
    "        \n",
    "        # 3. Quest√µes em discuss√£o\n",
    "        #prompt_3 = \"A partir das informa√ß√µes abaixo, escreva at√© 5 principais quest√µes comuns em discuss√£o nos processos, o retorno n√£o precisa ser em formato de pergunta:\\n\\n\" + questoes\n",
    "        #texto_3 = invoke(prompt_3, modelo, token)\n",
    "        #print(\"\\n‚ùì Quest√µes em discuss√£o:\")\n",
    "        #print(texto_3)\n",
    "        texto_3 = \"\"\n",
    "\n",
    "        # 4. Solu√ß√µes propostas\n",
    "        #prompt_4 = \"A partir das informa√ß√µes abaixo, escreva um resumo em at√© 500 caracteres das solu√ß√µes propostas comuns nos processos:\\n\\n\" + solucoes\n",
    "        #texto_4 = invoke(prompt_4, modelo, token)\n",
    "        #print(\"\\nüí° Solu√ß√µes propostas:\")\n",
    "       # print(texto_4)\n",
    "        texto_4 = \"\"\n",
    "        \n",
    "        # 5. Teses jur√≠dicas\n",
    "        #prompt_5 = \"A partir das informa√ß√µes abaixo, escreva um resumo em at√© 500 caracteres das teses jur√≠dicas comuns nesses processos:\\n\\n\" + teses\n",
    "        #texto_5 = invoke(prompt_5, modelo, token)\n",
    "        #print(\"\\n‚öñÔ∏è Teses jur√≠dicas:\")\n",
    "        #print(texto_5)\n",
    "        texto_5 = \"\"\n",
    "        \n",
    "        # Atualiza apenas uma vez por topico LLM\n",
    "        cur.execute(\"\"\"\n",
    "            UPDATE processos SET \n",
    "                descricao_curta_cluster = %s,\n",
    "                descricao_longa_cluster = %s,\n",
    "                questoes_discussao_cluster = %s,\n",
    "                solucoes_propostas_cluster = %s,\n",
    "                teses_cluster = %s\n",
    "            WHERE descricao_topico_llm = %s\n",
    "        \"\"\", (\n",
    "            texto_1, texto_2, texto_3, texto_4, texto_5, topico\n",
    "        ))\n",
    "        conn.commit()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "gerar_e_salvar_clusters(\"pixtral-12b\", get_token())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d40f41-e01a-43c6-a227-05b32b8bf9a1",
   "metadata": {},
   "source": [
    "## Agrupando os t√≥picos\n",
    "### 1 - Gera o embedding do nome do t√≥pico + descri√ß√£o curta (isso foi testado em v√°rias estrategias diferentes)\n",
    "\n",
    "### 2 - Cria uma matriz de similaridade de cada par de topicos onde o valor da c√©lula √© a similaridade entr5e os topicos\n",
    "\n",
    "### 3 - Pergunta ao LLM, para aqueles pares com similaridade maior que um limiar, se eles poderiam ser agrupados\n",
    "\n",
    "### 4 - Gerra a matriz de similiaridade de cada par de topicos onde o valor da c√©lula √© 1, caso os topicos sejam semelhantes ou 0 caso n√£o sejam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641117e1-2a7e-41b1-a57b-7d42ca194ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PAR√ÇMETROS AJUST√ÅVEIS\n",
    "# =========================\n",
    "DB_NAME = \"PROCESSOS\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASS = \"\"\n",
    "DB_HOST = \"\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "BERT_LOCAL_PATH = \"C:/Users/Loreane/Documents/bert\"  # caminho local do BERTimbau\n",
    "MAX_LENGTH = 512\n",
    "LIMIAR_MUITO_PARECIDO = 0.80     # limiar para enviar par ao LLM\n",
    "\n",
    "CSV_SIMILARIDADE = \"matriz_similaridade_topicos.csv\"\n",
    "CSV_BINARIA = \"matriz_mesmo_problema_llm.csv\"\n",
    "\n",
    "LLM_MODELO = \"pixtral-12b\"\n",
    "LLM_DELAY_S = 0.05               # atraso entre chamadas\n",
    "CASAS_PRINT = 3                  # casas decimais para imprimir similaridade\n",
    "\n",
    "# =========================\n",
    "# 0) Autentica√ß√£o e chamada ao LLM (SERPRO)\n",
    "# =========================\n",
    "token = None\n",
    "last_token_time = 0.0\n",
    "\n",
    "def get_token():\n",
    "    client_id = ''\n",
    "    client_secret = ''\n",
    "    result = requests.request(\n",
    "        'POST',\n",
    "        \"...\",\n",
    "        data={\"grant_type\": \"client_credentials\"},\n",
    "        auth=(client_id, client_secret),\n",
    "        timeout=60\n",
    "    )\n",
    "    if result.ok:\n",
    "        return result.json()['access_token']\n",
    "    else:\n",
    "        raise Exception(f\"Erro ao obter o token: {result.text}\")\n",
    "\n",
    "def get_valid_token():\n",
    "    global token, last_token_time\n",
    "    current_time = time.time()\n",
    "    if token is None or (current_time - last_token_time) > 20 * 60:  # 20 minutos\n",
    "        token = get_token()\n",
    "        last_token_time = current_time\n",
    "        print(\"Novo token obtido.\")\n",
    "    return token\n",
    "\n",
    "def invoke(prompt, modelo, token, temperature=0, max_tokens=8, stream=False):\n",
    "    payload_data = {\n",
    "        \"model\": modelo,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stream\": stream\n",
    "    }\n",
    "    result = requests.request(\n",
    "        \"POST\",\n",
    "        \"...\",\n",
    "        data=json.dumps(payload_data),\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        },\n",
    "        timeout=120\n",
    "    )\n",
    "    if result.ok:\n",
    "        res = result.json()\n",
    "        return res[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise RuntimeError(f\"Erro no LLM: {result.status_code} - {result.text}\")\n",
    "\n",
    "# =========================\n",
    "# 1) Conex√£o e busca de t√≥picos\n",
    "# =========================\n",
    "def conectar_banco():\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def buscar_topicos(conn):\n",
    "    sql = \"\"\"\n",
    "        SELECT\n",
    "            descricao_topico_llm,\n",
    "            descricao_curta_cluster,\n",
    "            questoes_discussao_cluster,\n",
    "            cor_cluster,\n",
    "            COUNT(*) AS total_registros\n",
    "        FROM processos\n",
    "        WHERE descricao_topico_llm IS NOT NULL\n",
    "          AND descricao_curta_cluster IS NOT NULL\n",
    "        GROUP BY\n",
    "            descricao_topico_llm,\n",
    "            descricao_curta_cluster,\n",
    "            questoes_discussao_cluster,\n",
    "            cor_cluster\n",
    "        ORDER BY total_registros DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql, conn)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 2) Preparar texto de cada t√≥pico\n",
    "# =========================\n",
    "def _safe_str(x):\n",
    "    return \"\" if x is None else str(x)\n",
    "\n",
    "def montar_texto_topico(row):\n",
    "    \"\"\"\n",
    "    Concatena: descricao_topico_llm [SEP] descricao_curta_cluster [SEP] questoes_discussao_cluster\n",
    "    (Atualmente est√° usando apenas o t√≠tulo para embedding, conforme seu ajuste.)\n",
    "    \"\"\"\n",
    "    p1 = _safe_str(row.get(\"descricao_topico_llm\", \"\"))\n",
    "    # Para usar tamb√©m as outras descri√ß√µes, descomente:\n",
    "    #p2 = _safe_str(row.get(\"descricao_curta_cluster\", \"\"))\n",
    "    # p3 = _safe_str(row.get(\"questoes_discussao_cluster\", \"\"))\n",
    "    p3 = p2 = \"\"\n",
    "    def _clean(s): return \" \".join(s.split()).strip()\n",
    "    return \" [SEP] \".join([_clean(p1), _clean(p2), _clean(p3)])\n",
    "\n",
    "# =========================\n",
    "# 3) Vetoriza√ß√£o com BERTimbau local (robusta a overflow)\n",
    "# =========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_LOCAL_PATH)\n",
    "model = AutoModel.from_pretrained(BERT_LOCAL_PATH).to(device)\n",
    "model.eval()\n",
    "\n",
    "def gerar_vetor(texto: str, max_length: int = MAX_LENGTH) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Embedding por mean pooling com m√°scara (ignora padding) + normaliza√ß√£o L2.\n",
    "    Robusto a estouro de tokens (alinha m√°scara ao tamanho real de sa√≠da do modelo).\n",
    "    Retorna np.ndarray shape (hidden_size,).\n",
    "    \"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        texto = \"\" if texto is None else str(texto)\n",
    "\n",
    "    # Respeita limites do modelo/tokenizer\n",
    "    model_max = int(getattr(model.config, \"max_position_embeddings\", 512))\n",
    "    tok_max = getattr(tokenizer, \"model_max_length\", model_max)\n",
    "    if tok_max is None or tok_max > 10_000:\n",
    "        tok_max = model_max\n",
    "    effective_max = int(min(max_length, model_max, tok_max))\n",
    "    effective_max = max(8, effective_max)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ins = tokenizer(\n",
    "            texto,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=effective_max\n",
    "        ).to(device)\n",
    "\n",
    "        out = model(**ins)\n",
    "        hidden = out.last_hidden_state              # [1, Tm, H]\n",
    "        seq_len = hidden.size(1)                    # Tm\n",
    "        attn = ins[\"attention_mask\"][:, :seq_len]   # [1, Tm]\n",
    "        mask = attn.unsqueeze(-1).expand(hidden.size()).float()\n",
    "\n",
    "        sent = (hidden * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-9)   # [1, H]\n",
    "        sent = F.normalize(sent, p=2, dim=1)                                   # [1, H]\n",
    "        return sent.squeeze(0).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "def embed_textos(textos):\n",
    "    \"\"\"Gera um vetor por texto chamando gerar_vetor().\"\"\"\n",
    "    vecs = [gerar_vetor(t) for t in tqdm(textos, desc=\"Gerando embeddings\")]\n",
    "    if not vecs:\n",
    "        dim = getattr(model.config, \"hidden_size\", 768)\n",
    "        return np.empty((0, dim), dtype=np.float32)\n",
    "    return np.vstack(vecs)\n",
    "\n",
    "# =========================\n",
    "# 4) Matriz de similaridade\n",
    "# =========================\n",
    "def matriz_similaridade(embs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Como os embeddings j√° est√£o normalizados (L2), o produto interno vira cosseno.\n",
    "    Retorna matriz S (N x N) com diag=1.0.\n",
    "    \"\"\"\n",
    "    if embs.size == 0:\n",
    "        return np.empty((0, 0), dtype=np.float32)\n",
    "    S = embs @ embs.T\n",
    "    np.fill_diagonal(S, 1.0)\n",
    "    return S.astype(np.float32)\n",
    "\n",
    "# =========================\n",
    "# 5) Impress√£o/CSV com r√≥tulos\n",
    "# =========================\n",
    "def imprimir_dataframe_com_rotulos(matriz, labels, casas=3, titulo=None):\n",
    "    \"\"\"\n",
    "    Imprime um DataFrame com r√≥tulos nas linhas e colunas.\n",
    "    \"\"\"\n",
    "    if titulo:\n",
    "        print(f\"\\n=== {titulo} ===\")\n",
    "    df = pd.DataFrame(np.round(matriz, casas), index=labels, columns=labels)\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    pd.set_option(\"display.width\", 200)\n",
    "    df\n",
    "\n",
    "def salvar_csv_com_rotulos(matriz, labels, path_csv):\n",
    "    \"\"\"\n",
    "    Salva CSV com r√≥tulos de linhas e colunas.\n",
    "    \"\"\"\n",
    "    df_full = pd.DataFrame(matriz, index=labels, columns=labels)\n",
    "    df_full.to_csv(path_csv, encoding=\"utf-8\", index=True)\n",
    "    print(f\"[OK] CSV salvo: {path_csv}\")\n",
    "\n",
    "# =========================\n",
    "# 6) Similaridade: pipeline + impress√£o\n",
    "# =========================\n",
    "def imprimir_matriz_similaridade(conn, arredondar=3, salvar_csv=CSV_SIMILARIDADE):\n",
    "    # 6.1 Buscar dados\n",
    "    df_top = buscar_topicos(conn)\n",
    "    if df_top.empty:\n",
    "        print(\"Nenhum t√≥pico encontrado.\")\n",
    "        return df_top, np.empty((0, 0)), pd.DataFrame()\n",
    "\n",
    "    # 6.2 Texto completo por t√≥pico\n",
    "    df_top[\"texto_full\"] = df_top.apply(montar_texto_topico, axis=1)\n",
    "\n",
    "    # 6.3 Embeddings\n",
    "    embs = embed_textos(df_top[\"texto_full\"].tolist())\n",
    "\n",
    "    # 6.4 Matriz de similaridade\n",
    "    S = matriz_similaridade(embs)\n",
    "\n",
    "    # 6.5 R√≥tulos √∫nicos (duplicados desambiguados)\n",
    "    labels = df_top[\"descricao_topico_llm\"].astype(str).tolist()\n",
    "    count = Counter(labels)\n",
    "    seen = defaultdict(int)\n",
    "    labels_uniq = []\n",
    "    for L in labels:\n",
    "        if count[L] > 1:\n",
    "            seen[L] += 1\n",
    "            labels_uniq.append(f\"{L} [{seen[L]}]\")\n",
    "        else:\n",
    "            labels_uniq.append(L)\n",
    "\n",
    "    # 6.6 Imprimir e salvar\n",
    "    imprimir_dataframe_com_rotulos(S, labels_uniq, casas=arredondar, titulo=\"MATRIZ DE SIMILARIDADE (cos)\")\n",
    "    if salvar_csv:\n",
    "        salvar_csv_com_rotulos(S, labels_uniq, salvar_csv)\n",
    "\n",
    "    # Retorna DataFrame com r√≥tulos nas colunas/√≠ndice\n",
    "    sim_df = pd.DataFrame(S, index=labels_uniq, columns=labels_uniq)\n",
    "    return df_top, embs, sim_df\n",
    "\n",
    "# =========================\n",
    "# 7) LLM: prompt e normaliza√ß√£o 1/0\n",
    "# =========================\n",
    "def construir_prompt_mesmo_problema(topico_a, desc_a, quest_a, topico_b, desc_b, quest_b):\n",
    "    qa = (quest_a or \"\").strip()\n",
    "    qb = (quest_b or \"\").strip()\n",
    "    return f\"\"\"\n",
    "Voc√™ √© um assistente jur√≠dico. Decida se os dois t√≥picos abaixo tratam essencialmente do MESMO PROBLEMA central,\n",
    "desconsiderando varia√ß√µes de reda√ß√£o. Responda APENAS com um √∫nico caractere: \"1\" (mesmo problema) ou \"0\" (problemas diferentes).\n",
    "\n",
    "T√≥pico A:\n",
    "- T√≠tulo: {topico_a}\n",
    "- Descri√ß√£o curta: {desc_a}\n",
    "\n",
    "T√≥pico B:\n",
    "- T√≠tulo: {topico_b}\n",
    "- Descri√ß√£o curta: {desc_b}\n",
    "\n",
    "Responda somente com 1 ou 0:\n",
    "\"\"\".strip()\n",
    "\n",
    "def normalizar_0_1(texto) -> int:\n",
    "    if not isinstance(texto, str):\n",
    "        return 0\n",
    "    t = texto.strip()\n",
    "    if t.startswith(\"1\"): return 1\n",
    "    if t.startswith(\"0\"): return 0\n",
    "    return 0\n",
    "\n",
    "# =========================\n",
    "# 8) Matriz bin√°ria NxN via LLM (consome df_top, sim_df)\n",
    "# =========================\n",
    "def construir_matriz_binaria_por_llm(\n",
    "    df_top: pd.DataFrame,\n",
    "    sim_df: pd.DataFrame,\n",
    "    limiar: float = LIMIAR_MUITO_PARECIDO,\n",
    "    modelo: str = LLM_MODELO,\n",
    "    delay_s: float = LLM_DELAY_S,\n",
    "    casas_print: int = 0,\n",
    "    csv_saida: str = CSV_BINARIA\n",
    "):\n",
    "    \"\"\"\n",
    "    Constr√≥i a matriz bin√°ria NxN (1 = mesmo problema; 0 = diferente) usando o LLM,\n",
    "    a partir de df_top e da matriz de similaridade sim_df retornados por imprimir_matriz_similaridade.\n",
    "    Imprime a matriz como DataFrame com nomes nas linhas e colunas e salva CSV.\n",
    "\n",
    "    Retorna:\n",
    "      - M (np.ndarray NxN)\n",
    "      - labels (lista de r√≥tulos)\n",
    "      - df_bin (DataFrame NxN com r√≥tulos)\n",
    "    \"\"\"\n",
    "    # 8.1 Extrai similaridade e r√≥tulos na MESMA ORDEM\n",
    "    S = sim_df.values.astype(float)\n",
    "    labels = list(sim_df.index)  # ordem j√° consistente entre √≠ndice e colunas\n",
    "    n = S.shape[0]\n",
    "\n",
    "    if n == 0:\n",
    "        print(\"Matriz de similaridade vazia. Nada a validar no LLM.\")\n",
    "        return np.empty((0, 0), dtype=np.int8), [], pd.DataFrame()\n",
    "\n",
    "    # 8.2 Preparar descri√ß√µes/quest√µes para prompts\n",
    "    topicos_df = df_top[\"descricao_topico_llm\"].astype(str).tolist()\n",
    "    descs_df   = df_top[\"descricao_curta_cluster\"].astype(str).tolist()\n",
    "    quests_df  = df_top.get(\"questoes_discussao_cluster\", pd.Series([\"\"] * len(df_top))).astype(str).tolist()\n",
    "\n",
    "    # mapa r√°pido por t√≠tulo ‚Üí (desc, quest)\n",
    "    mapa_por_titulo = {}\n",
    "    for t, d, q in zip(topicos_df, descs_df, quests_df):\n",
    "        if t not in mapa_por_titulo:\n",
    "            mapa_por_titulo[t] = (d, q)\n",
    "\n",
    "    def obter_desc_e_quest_por_pos(i):\n",
    "        titulo = labels[i]\n",
    "        if titulo in mapa_por_titulo:\n",
    "            return mapa_por_titulo[titulo]\n",
    "        # fallback pela posi√ß√£o (assumindo mesma execu√ß√£o/ordem)\n",
    "        if i < len(descs_df):\n",
    "            return descs_df[i], quests_df[i]\n",
    "        return \"\", \"\"\n",
    "\n",
    "    # 8.3 Matriz 1/0\n",
    "    M = np.zeros((n, n), dtype=np.int8)\n",
    "    np.fill_diagonal(M, 1)\n",
    "\n",
    "    print(f\"\\n[LLM] Avaliando pares com similaridade >= {limiar:.3f} (resposta: 1/0)...\")\n",
    "    for i in range(n):\n",
    "        di, qi = obter_desc_e_quest_por_pos(i)\n",
    "        for j in range(i + 1, n):\n",
    "            if S[i, j] >= limiar:\n",
    "                dj, qj = obter_desc_e_quest_por_pos(j)\n",
    "                prompt = construir_prompt_mesmo_problema(\n",
    "                    labels[i], di, qi,\n",
    "                    labels[j], dj, qj\n",
    "                )\n",
    "                # Logs opcionais (tire se quiser rodar silencioso)\n",
    "                clear_output(wait=True)\n",
    "                print(f\"[{i},{j}] {labels[i]}  ‚Üî  {labels[j]}\\n\")\n",
    "                print(prompt)\n",
    "\n",
    "                try:\n",
    "                    tok = get_valid_token()\n",
    "                    resp = invoke(prompt, modelo, tok, temperature=0, max_tokens=8, stream=False)\n",
    "                    #bit = normalizar_0_1(resp)\n",
    "                    bit = resp\n",
    "                    print(f\"LLM ‚Üí {resp!r}  ‚áí  {bit}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Erro LLM no par ({i},{j}) '{labels[i]}' vs '{labels[j]}': {e}\")\n",
    "                    bit = 0\n",
    "\n",
    "                M[i, j] = M[j, i] = bit\n",
    "                time.sleep(delay_s)\n",
    "            else:\n",
    "                M[i, j] = M[j, i] = 0\n",
    "\n",
    "    # 8.4 Salvar e imprimir com r√≥tulos\n",
    "    if csv_saida:\n",
    "        salvar_csv_com_rotulos(M, labels, csv_saida)\n",
    "    imprimir_dataframe_com_rotulos(M, labels, casas=casas_print, titulo=\"MATRIZ MESMO PROBLEMA (LLM) ‚Äî 1/0\")\n",
    "\n",
    "    df_bin = pd.DataFrame(M, index=labels, columns=labels)\n",
    "    return M, labels, df_bin\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393d242-9030-4648-9ab4-832d5512ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = conectar_banco()\n",
    "# 1) Similaridade\n",
    "df_top, embs, sim_df = imprimir_matriz_similaridade(\n",
    "            conn,\n",
    "            arredondar=CASAS_PRINT,\n",
    "            salvar_csv=CSV_SIMILARIDADE\n",
    "        )\n",
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55797f84-b096-4ab4-bc8f-de5313eb402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 2) Matriz bin√°ria via LLM (executar ap√≥s a similaridade)\n",
    "M, labels, df_bin = construir_matriz_binaria_por_llm(\n",
    "        df_top=df_top,\n",
    "        sim_df=sim_df,\n",
    "        limiar=0.75,\n",
    "        modelo=LLM_MODELO,\n",
    "        delay_s=LLM_DELAY_S,\n",
    "        casas_print=0,\n",
    "        csv_saida=CSV_BINARIA\n",
    "    )\n",
    "\n",
    "df_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbfd154-cad3-4caa-a471-988f11d42a15",
   "metadata": {},
   "source": [
    "## AGRUPAMENTO: Realiza a busca de grupos no grafo correspondente a matriz\n",
    "### 1 cria o grafo (com op√ß√£o de exigir reciprocidade ou n√£o),\n",
    "### 2 acha os grupos por busca em largura (BFS), Agrupa apenas se o elemento a ser agrupado possui similaridade de at√© um limiar com os demais\n",
    "### 3 imprime os grupos em ordem decrescente de tamanho,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da103f6-744a-4f23-9c05-5a788e1673f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grupos_estritos_por_binaria_e_similaridade(\n",
    "    df_bin: pd.DataFrame,\n",
    "    sim_df: pd.DataFrame,\n",
    "    thr: float = 0.70,                 # exige > thr com TODOS do grupo\n",
    "    exigir_mutual: bool = False,       # True: precisa A[i,j]==1 e A[j,i]==1\n",
    "    incluir_isolados: bool = True,     # mant√©m t√≥picos sem conex√µes como grupos unit√°rios\n",
    "    df_top: Optional[pd.DataFrame] = None  # para escolher \"l√≠der\" pelo total_registros\n",
    "):\n",
    "    # --- 1) Preparar matriz bin√°ria e sim√©trica conforme regra ---\n",
    "    labels = list(df_bin.index)\n",
    "    assert labels == list(df_bin.columns) == list(sim_df.index) == list(sim_df.columns), \\\n",
    "        \"df_bin e sim_df precisam ter a MESMA ordem de linhas/colunas\"\n",
    "\n",
    "    A = df_bin.applymap(lambda x: 1 if str(x).strip().startswith(\"1\") else 0).values.astype(np.int8)\n",
    "    if exigir_mutual:\n",
    "        A_und = (A & A.T).astype(np.int8)\n",
    "    else:\n",
    "        A_und = (A | A.T).astype(np.int8)\n",
    "\n",
    "    # similaridade\n",
    "    S = sim_df.values.astype(float)\n",
    "    np.fill_diagonal(A_und, 1)  # um n√≥ conecta a si mesmo\n",
    "\n",
    "    n = len(labels)\n",
    "    usados = np.zeros(n, dtype=bool)\n",
    "\n",
    "    # grau (n¬∫ de conex√µes v√°lidas) para ordenar seeds\n",
    "    graus = A_und.sum(axis=1)\n",
    "    seeds = np.argsort(-graus)  # decrescente\n",
    "\n",
    "    grupos = []\n",
    "    for s in seeds:\n",
    "        if usados[s]:\n",
    "            continue\n",
    "\n",
    "        # se n√£o quer incluir isolados e s n√£o tem vizinhos, pule\n",
    "        tem_viz = (A_und[s].sum() - 1) > 0  # desconsidera auto-conex√£o\n",
    "        if not incluir_isolados and not tem_viz:\n",
    "            usados[s] = True\n",
    "            continue\n",
    "\n",
    "        # inicia grupo com seed s\n",
    "        grupo = [s]\n",
    "        usados[s] = True\n",
    "\n",
    "        # candidatos eleg√≠veis: conectados ao seed e ainda n√£o usados\n",
    "        cand = [i for i in range(n) if (i != s) and (not usados[i]) and (A_und[s, i] == 1)]\n",
    "\n",
    "        # estrat√©gia gulosa: s√≥ entra se respeitar TODAS as arestas e similaridade > thr com TODOS do grupo\n",
    "        # repete varrendo enquanto conseguir incluir algu√©m\n",
    "        mudou = True\n",
    "        while mudou:\n",
    "            mudou = False\n",
    "            novos = []\n",
    "            for i in cand:\n",
    "                if usados[i]:\n",
    "                    continue\n",
    "                # precisa aresta bin√°ria com TODOS do grupo...\n",
    "                if not np.all(A_und[i, grupo] == 1):\n",
    "                    continue\n",
    "                # ...e similaridade > thr com TODOS do grupo\n",
    "                if not np.all(S[i, grupo] > thr):\n",
    "                    continue\n",
    "                novos.append(i)\n",
    "\n",
    "            if novos:\n",
    "                # para estabilidade, adicione em ordem por (grau decrescente, label)\n",
    "                novos.sort(key=lambda j: (-graus[j], labels[j].lower()))\n",
    "                for j in novos:\n",
    "                    if not usados[j]:\n",
    "                        grupo.append(j)\n",
    "                        usados[j] = True\n",
    "                        mudou = True\n",
    "\n",
    "                # atualiza candidatos: vizinhos de qualquer membro do grupo, n√£o usados\n",
    "                vizinhos = np.where(A_und[grupo].any(axis=0))[0]\n",
    "                cand = [i for i in vizinhos if (not usados[i]) and (i not in grupo)]\n",
    "\n",
    "        # ordena r√≥tulos do grupo\n",
    "        grupo_sorted = sorted(grupo, key=lambda idx: labels[idx].lower())\n",
    "        grupos.append(grupo_sorted)\n",
    "\n",
    "    # ordena grupos por tamanho e pelo primeiro r√≥tulo\n",
    "    grupos.sort(key=lambda g: (-len(g), [labels[i].lower() for i in g]))\n",
    "\n",
    "    # montar sa√≠da leg√≠vel e l√≠der opcional\n",
    "    linhas, grupos_legiveis = [], []\n",
    "    for gid, idxs in enumerate(grupos, start=1):\n",
    "        rotulos = [labels[i] for i in idxs]\n",
    "        lider = rotulos[0]\n",
    "        if df_top is not None and {\"descricao_topico_llm\", \"total_registros\"}.issubset(df_top.columns):\n",
    "            sub = df_top[df_top[\"descricao_topico_llm\"].astype(str).isin(rotulos)]\n",
    "            if not sub.empty:\n",
    "                lider = sub.sort_values(\"total_registros\", ascending=False).iloc[0][\"descricao_topico_llm\"]\n",
    "        grupos_legiveis.append(rotulos)\n",
    "        for r in rotulos:\n",
    "            linhas.append({\n",
    "                \"group_id\": gid,\n",
    "                \"leader\": lider,\n",
    "                \"topic\": r,\n",
    "                \"group_size\": len(rotulos)\n",
    "            })\n",
    "\n",
    "    df_grupos = pd.DataFrame(linhas, columns=[\"group_id\", \"leader\", \"topic\", \"group_size\"])\n",
    "    return grupos_legiveis, df_grupos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fe645-549c-4ba0-8bcf-40d533f8cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos, df_groups = grupos_estritos_por_binaria_e_similaridade(\n",
    "    df_bin=df_bin,\n",
    "    sim_df=sim_df,\n",
    "    thr=0.75,        # seu limiar (ex.: 0.9)\n",
    "    exigir_mutual=False  # se quiser mais conservador, troque para True\n",
    ")\n",
    "\n",
    "for i, g in enumerate(grupos, 1):\n",
    "    print(f\"Grupo {i} ({len(g)}):\")\n",
    "    for t in g:\n",
    "        print(\"  -\", t)\n",
    "    print()\n",
    "\n",
    "# opcional: salvar\n",
    "df_groups.to_csv(\"grupos_conectividade.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405c0ed-0c2c-4fbc-a39b-c48df1467822",
   "metadata": {},
   "source": [
    "# Atualizar os integrantes do grupo, escolhendo o representante como o que tem maior qtd de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17329a75-e3e6-4097-bafc-2fd2b44fcf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helper: escolhe o representante (maior COUNT(*)) dentro de um grupo de t√≥picos ---\n",
    "def escolher_representante(conn, topics):\n",
    "    \"\"\"\n",
    "    Retorna um dict do representante do grupo:\n",
    "    {descricao_topico_llm, numero_topico_llm, cor_cluster, total}\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT \n",
    "                descricao_topico_llm,\n",
    "                numero_topico_llm,\n",
    "                cor_cluster,\n",
    "                descricao_topico_bertopic_padrao,\n",
    "                COUNT(*) AS total\n",
    "            FROM processos\n",
    "            WHERE descricao_topico_llm = ANY(%s)\n",
    "            GROUP BY descricao_topico_llm, numero_topico_llm, cor_cluster,descricao_topico_bertopic_padrao\n",
    "            ORDER BY total DESC\n",
    "            LIMIT 1\n",
    "        \"\"\", (topics,))\n",
    "        row = cur.fetchone()\n",
    "        if not row:\n",
    "            return None\n",
    "        return {\n",
    "            \"descricao_topico_llm\": row[0],\n",
    "            \"numero_topico_llm\": row[1],\n",
    "            \"cor_cluster\": row[2],\n",
    "            \"descricao_topico_bertopic_padrao\": row[3],  \n",
    "            \"total\": row[4],                             \n",
    "        }\n",
    "# --- helper: atualiza todo o grupo para o representante ---\n",
    "def atualizar_grupo_para_representante(conn, topics, rep):\n",
    "    \"\"\"\n",
    "    Atualiza todos os registros cujos t√≥picos estejam em 'topics'\n",
    "    para os campos do representante 'rep'.\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            UPDATE processos\n",
    "            SET\n",
    "                descricao_topico_llm = %s,\n",
    "                numero_topico_llm   = %s,\n",
    "                cor_cluster         = %s,\n",
    "                descricao_topico_bertopic_padrao = %s\n",
    "            WHERE descricao_topico_llm = ANY(%s)\n",
    "        \"\"\", (\n",
    "            rep[\"descricao_topico_llm\"],\n",
    "            rep[\"numero_topico_llm\"],\n",
    "            rep[\"cor_cluster\"],\n",
    "            rep[\"descricao_topico_bertopic_padrao\"],\n",
    "            topics\n",
    "        ))\n",
    "\n",
    "# --- pipeline principal ---\n",
    "def aplicar_grupos_por_conectividade(conn, grupos):\n",
    "    \"\"\"\n",
    "    Para cada grupo (lista de t√≠tulos de t√≥pico):\n",
    "      1) escolhe o representante (maior COUNT(*));\n",
    "      2) atualiza todos os registros dos t√≥picos do grupo para os campos do representante.\n",
    "    Tudo numa √∫nica transa√ß√£o.\n",
    "    \"\"\"\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            pass  # s√≥ para abrir a transa√ß√£o via context manager\n",
    "\n",
    "        for gid, topics in enumerate(grupos, start=1):\n",
    "            # sanitiza lista: remove vazios/duplicados\n",
    "            topics = sorted({str(t).strip() for t in topics if t and str(t).strip()})\n",
    "            if not topics:\n",
    "                continue\n",
    "\n",
    "            rep = escolher_representante(conn, topics)\n",
    "            if not rep:\n",
    "                print(f\"[Grupo {gid}] Sem registros para: {topics}\")\n",
    "                continue\n",
    "\n",
    "            atualizar_grupo_para_representante(conn, topics, rep)\n",
    "            print(f\"[Grupo {gid}] {topics}  ‚Üí  representante: \"\n",
    "                  f\"{rep['descricao_topico_llm']} (n¬∫ {rep['numero_topico_llm']}, cor {rep['cor_cluster']}, total={rep['total']})\")\n",
    "\n",
    "    print(\"‚úÖ Atualiza√ß√µes conclu√≠das.\")\n",
    "\n",
    "conn = get_connection()\n",
    "aplicar_grupos_por_conectividade(conn, grupos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906c401-942c-4f74-b8d1-6f553b5f18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo novamente a descri√ß√£o e titulo de cada cluster, pois agora foram agrupados e √© interessante atualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf40187-f095-4b2f-b4bf-ff7e856e7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_e_salvar_detalhes_cluster(modelo, token):\n",
    "    conn = get_connection()\n",
    "    cur = conn.cursor()\n",
    "    modelo = 'pixtral-12b'\n",
    "\n",
    "    # =========================\n",
    "    # 0) Limpar campos antigos antes de atualizar\n",
    "    # =========================\n",
    "    print(\"üßπ Limpando campos anteriores dos clusters...\")\n",
    "    cur.execute(\"\"\"\n",
    "        UPDATE processos SET\n",
    "            descricao_curta_cluster = NULL,\n",
    "            descricao_longa_cluster = NULL,\n",
    "            questoes_discussao_cluster = NULL,\n",
    "            solucoes_propostas_cluster = NULL,\n",
    "            teses_cluster = NULL\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Campos limpos com sucesso.\\n\")\n",
    "\n",
    "    df = pd.read_sql_query(\"\"\"\n",
    "        SELECT id, numero_processo_tribunal, descricao_caso, questoes_em_discussao, \n",
    "               solucoes_propostas, tese, numero_topico_llm, descricao_topico_llm, \n",
    "               proximo_do_centroid, descricao_topico_bertopic_padrao\n",
    "        FROM processos \n",
    "        WHERE proximo_do_centroid = 1\n",
    "    \"\"\", conn)\n",
    "\n",
    "    grupos = df.groupby(\"descricao_topico_llm\")\n",
    "\n",
    "    for topico, grupo in grupos:\n",
    "        casos = \"\\n\\n\".join(grupo['descricao_caso'].dropna())\n",
    "        keywords = \"\\n\\n Palavras chave:\".join(grupo['descricao_caso'].dropna())\n",
    "        questoes = \"\\n\\n\".join(grupo['questoes_em_discussao'].dropna())\n",
    "        solucoes = \"\\n\\n\".join(grupo['solucoes_propostas'].dropna())\n",
    "        teses = \"\\n\\n\".join(grupo['tese'].dropna())\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"\\n\\n===========================\")\n",
    "        print(f\"üîé T√≥pico {topico} - {grupo['descricao_topico_llm'].iloc[0]}\")\n",
    "        print(f\"IDs: {grupo['id'].tolist()}\")\n",
    "\n",
    "        # 0. T√≠tulo do cluster\n",
    "        prompt_0 = \"\"\"Voc√™ √© um assistente inteligente de extra√ß√£o de t√≥picos, especializado em nomear t√≥picos de forma curta, clara e amig√°vel, com base em textos representativos e palavras-chave. \n",
    "        Seu objetivo √© criar um **r√≥tulo conciso** que represente o problema central em comum dos conte√∫dos discutidos no t√≥pico, facilitando a identifica√ß√£o do assunto por usu√°rios finais. \n",
    "        \n",
    "        Siga as diretrizes abaixo:\n",
    "        - N√£o inclua o termo \"MEI\" no nome do t√≥pico.\n",
    "        - O nome deve ter de 1 a 3 palavras.\n",
    "        - N√£o cite nome de pessoas, locais ou institui√ß√µes.\n",
    "\n",
    "        Responda apenas o nome do r√≥tulo, sem asteriscos.\n",
    "        \"\"\" + keywords + casos\n",
    "        texto_0 = invoke(prompt_0, modelo, token)\n",
    "        print(\"\\nüìå T√≠tulo:\")\n",
    "        print(texto_0)\n",
    "\n",
    "        # 1. Descri√ß√£o curta\n",
    "        prompt_1 = \"Voc√™ √© um assistente jur√≠dico. Com base nas descri√ß√µes dos casos abaixo, escreva um resumo curto (1 par√°grafo com at√© 150 caracteres) que represente o tema comum entre os processos:\\n\\n\" + casos\n",
    "        #print(prompt_1)\n",
    "        texto_1 = invoke(prompt_1, modelo, token)\n",
    "        \n",
    "        print(\"\\nüìå Descri√ß√£o curta:\")\n",
    "        print(texto_1)\n",
    "\n",
    "        # 2. Descri√ß√£o longa\n",
    "        prompt_2 = \"Voc√™ √© um assistente jur√≠dico. Com base nas descri√ß√µes dos casos abaixo, escreva um texto descritivo em at√© 500 caracteres sobre o tema comum desses processos:\\n\\n\" + casos\n",
    "        texto_2 = invoke(prompt_2, modelo, token)\n",
    "        print(\"\\nüìò Descri√ß√£o longa:\")\n",
    "        print(texto_2)\n",
    "        \n",
    "        # 3. Quest√µes em discuss√£o\n",
    "        prompt_3 = \"A partir das informa√ß√µes abaixo, escreva at√© 5 principais quest√µes comuns em discuss√£o nos processos, o retorno n√£o precisa ser em formato de pergunta:\\n\\n\" + questoes\n",
    "        texto_3 = invoke(prompt_3, modelo, token)\n",
    "        print(\"\\n‚ùì Quest√µes em discuss√£o:\")\n",
    "        print(texto_3)\n",
    "\n",
    "\n",
    "        # 4. Solu√ß√µes propostas\n",
    "        prompt_4 = \"A partir das informa√ß√µes abaixo, escreva um resumo em at√© 500 caracteres das solu√ß√µes propostas comuns nos processos:\\n\\n\" + solucoes\n",
    "        texto_4 = invoke(prompt_4, modelo, token)\n",
    "        print(\"\\nüí° Solu√ß√µes propostas:\")\n",
    "        print(texto_4)\n",
    "        \n",
    "        # 5. Teses jur√≠dicas\n",
    "        prompt_5 = \"A partir das informa√ß√µes abaixo, escreva um resumo em at√© 500 caracteres das teses jur√≠dicas comuns nesses processos:\\n\\n\" + teses\n",
    "        texto_5 = invoke(prompt_5, modelo, token)\n",
    "        print(\"\\n‚öñÔ∏è Teses jur√≠dicas:\")\n",
    "        print(texto_5)    \n",
    "        \n",
    "        # Atualiza apenas uma vez por topico LLM\n",
    "        cur.execute(\"\"\"\n",
    "            UPDATE processos SET \n",
    "                descricao_topico_llm = %s,\n",
    "                descricao_curta_cluster = %s,\n",
    "                descricao_longa_cluster = %s,\n",
    "                questoes_discussao_cluster = %s,\n",
    "                solucoes_propostas_cluster = %s,\n",
    "                teses_cluster = %s\n",
    "            WHERE descricao_topico_llm = %s\n",
    "        \"\"\", (\n",
    "            texto_0, texto_1, texto_2, texto_3, texto_4, texto_5, topico\n",
    "        ))\n",
    "        conn.commit()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef6542-5e74-4f2d-a599-4fdf2d9fe63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gerar_e_salvar_detalhes_cluster(\"pixtral-12b\", get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb1b11-7833-41c7-9f73-7b3a9648a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduzir_nome_cluster(modelo, token):\n",
    "    conn = get_connection()\n",
    "    cur = conn.cursor()\n",
    "    modelo = 'pixtral-12b'\n",
    "\n",
    "    df = pd.read_sql_query(\"\"\"\n",
    "        SELECT numero_topico_llm, descricao_topico_llm, descricao_curta_cluster\n",
    "        FROM processos \n",
    "        WHERE proximo_do_centroid = 1\n",
    "    \"\"\", conn)\n",
    "\n",
    "    grupos = df.groupby(\"descricao_topico_llm\")\n",
    "\n",
    "    for topico, grupo in grupos:\n",
    "        titulo = \"\\n\\nNome do T√≥pico:\".join(grupo['descricao_topico_llm'].dropna())\n",
    "        descricao = \"\\n\\nDescri√ß√£o do T√≥pico:\".join(grupo['descricao_curta_cluster'].dropna())\n",
    "        clear_output(wait=True)\n",
    "        print(f\"\\n\\n===========================\")\n",
    "        print(f\"üîé T√≥pico {topico} - {grupo['descricao_topico_llm'].iloc[0]}\")\n",
    "\n",
    "        # 0. T√≠tulo do cluster\n",
    "        prompt_0 = \"\"\"Traduza para Ingl√™s o nome do t√≥pico abaixo. Lembre que s√£o termos jur√≠dicos. Responda apenas o nome do t√≥pico em ingl√™s , sem asteriscos.\n",
    "        \"\"\" + titulo + descricao\n",
    "        texto_0 = invoke(prompt_0, modelo, token)\n",
    "        print(\"\\nüìå T√≠tulo:\")\n",
    "        print(texto_0)\n",
    "        # Atualiza apenas uma vez por topico LLM\n",
    "        cur.execute(\"\"\"\n",
    "            UPDATE processos SET \n",
    "                descricao_topico_llm_ingles = %s\n",
    "            WHERE descricao_topico_llm = %s\n",
    "        \"\"\", (\n",
    "            texto_0, topico\n",
    "        ))\n",
    "        conn.commit()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311c26b-1312-4b5b-b207-79915f72a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "traduzir_nome_cluster(\"pixtral-12b\", get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dbe28e-562b-4166-939c-78477d3e7ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b39647-7e0c-4055-9eee-11f8531e1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_e_salvar_detalhes_cluster(modelo, token):\n",
    "    conn = get_connection()\n",
    "    cur = conn.cursor()\n",
    "    modelo = 'pixtral-12b'\n",
    "\n",
    "    # =========================\n",
    "    # 0) Limpar campos antigos antes de atualizar\n",
    "    # =========================\n",
    "    print(\"üßπ Limpando campos anteriores dos clusters...\")\n",
    "    cur.execute(\"\"\"\n",
    "        UPDATE processos SET\n",
    "            descricao_curta_cluster = NULL,\n",
    "            descricao_longa_cluster = NULL,\n",
    "            questoes_discussao_cluster = NULL,\n",
    "            solucoes_propostas_cluster = NULL,\n",
    "            teses_cluster = NULL\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Campos limpos com sucesso.\\n\")\n",
    "\n",
    "    df = pd.read_sql_query(\"\"\"\n",
    "        SELECT id, numero_processo_tribunal, descricao_caso, questoes_em_discussao, \n",
    "               solucoes_propostas, tese, numero_topico_llm, descricao_topico_llm, \n",
    "               proximo_do_centroid, descricao_topico_bertopic_padrao\n",
    "        FROM processos \n",
    "        WHERE proximo_do_centroid = 1\n",
    "    \"\"\", conn)\n",
    "\n",
    "    grupos = df.groupby(\"descricao_topico_llm\")\n",
    "\n",
    "    for topico, grupo in grupos:\n",
    "        casos = \"\\n\\n\".join(grupo['descricao_caso'].dropna())\n",
    "        keywords = \"\\n\\n Palavras chave:\".join(grupo['descricao_caso'].dropna())\n",
    "        questoes = \"\\n\\n\".join(grupo['questoes_em_discussao'].dropna())\n",
    "        solucoes = \"\\n\\n\".join(grupo['solucoes_propostas'].dropna())\n",
    "        teses = \"\\n\\n\".join(grupo['tese'].dropna())\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"\\n\\n===========================\")\n",
    "        print(f\"üîé T√≥pico {topico} - {grupo['descricao_topico_llm'].iloc[0]}\")\n",
    "        print(f\"IDs: {grupo['id'].tolist()}\")\n",
    "\n",
    "       \n",
    "\n",
    "        # 1. Descri√ß√£o curta\n",
    "        prompt_1 = \"Voc√™ √© um assistente jur√≠dico. Com base nas descri√ß√µes dos casos abaixo, escreva um resumo curto (1 par√°grafo com at√© 150 caracteres) que represente o tema comum entre os processos:\\n\\n\" + casos\n",
    "        #print(prompt_1)\n",
    "        texto_1 = invoke(prompt_1, modelo, token)\n",
    "        \n",
    "        print(\"\\nüìå Descri√ß√£o curta:\")\n",
    "        print(texto_1)\n",
    "\n",
    "        # 2. Descri√ß√£o longa\n",
    "        prompt_2 = \"Voc√™ √© um assistente jur√≠dico. Com base nas descri√ß√µes dos casos abaixo, escreva um texto descritivo em at√© 500 caracteres sobre o tema comum desses processos:\\n\\n\" + casos\n",
    "        texto_2 = invoke(prompt_2, modelo, token)\n",
    "        print(\"\\nüìò Descri√ß√£o longa:\")\n",
    "        print(texto_2)\n",
    "        \n",
    "        # 3. Quest√µes em discuss√£o\n",
    "        prompt_3 = \"A partir das informa√ß√µes abaixo, escreva at√© 5 principais quest√µes comuns em discuss√£o nos processos, o retorno n√£o precisa ser em formato de pergunta:\\n\\n\" + questoes\n",
    "        texto_3 = invoke(prompt_3, modelo, token)\n",
    "        print(\"\\n‚ùì Quest√µes em discuss√£o:\")\n",
    "        print(texto_3)\n",
    "\n",
    "\n",
    "        # 4. Solu√ß√µes propostas\n",
    "        prompt_4 = \"A partir das informa√ß√µes abaixo, escreva um resumo em at√© 500 caracteres das solu√ß√µes propostas comuns nos processos:\\n\\n\" + solucoes\n",
    "        texto_4 = invoke(prompt_4, modelo, token)\n",
    "        print(\"\\nüí° Solu√ß√µes propostas:\")\n",
    "        print(texto_4)\n",
    "        \n",
    "        # 5. Teses jur√≠dicas\n",
    "        prompt_5 = \"A partir das informa√ß√µes abaixo, escreva um resumo em at√© 500 caracteres das teses jur√≠dicas comuns nesses processos:\\n\\n\" + teses\n",
    "        texto_5 = invoke(prompt_5, modelo, token)\n",
    "        print(\"\\n‚öñÔ∏è Teses jur√≠dicas:\")\n",
    "        print(texto_5)    \n",
    "        \n",
    "        # Atualiza apenas uma vez por topico LLM\n",
    "        cur.execute(\"\"\"\n",
    "            UPDATE processos SET \n",
    "                descricao_curta_cluster = %s,\n",
    "                descricao_longa_cluster = %s,\n",
    "                questoes_discussao_cluster = %s,\n",
    "                solucoes_propostas_cluster = %s,\n",
    "                teses_cluster = %s\n",
    "            WHERE descricao_topico_llm = %s\n",
    "        \"\"\", ( texto_1, texto_2, texto_3, texto_4, texto_5, topico\n",
    "        ))\n",
    "        conn.commit()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030ada44-b91f-41de-a293-5d1d63e7ccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===========================\n",
      "üîé T√≥pico V√≠nculo Empregat√≠cio - V√≠nculo Empregat√≠cio\n",
      "IDs: [14323, 36290, 43748, 24618, 13719, 16660, 44081, 16360, 25271, 36312, 36045, 8247, 6454, 35651, 24780, 8525, 6630, 7259, 5973, 7100, 6178, 24775, 18253, 36691, 17141, 8396, 7386, 36541, 11209, 28501, 43903, 23467, 24434, 44427, 14912, 15737, 7385, 44500, 28578, 44934, 26498, 5967, 44397, 25583, 5985, 36452, 9139, 16946, 23714, 25338, 35235, 7976, 8274, 44825, 11256, 44780, 23838, 42309, 27824, 15328, 15885, 8384, 27188, 43025, 9463, 13210, 30897, 32061, 6406, 14344, 35858, 11443, 12327, 6415, 36388, 9191, 12463, 14611, 35459, 8301, 45020, 8373, 17374, 45160, 4808, 23204, 7179, 42775, 31896, 24832, 27675, 15219, 18598, 28239, 11210, 42956, 7895, 12902, 8257, 35077, 14089, 27363, 8679, 36301, 5698, 8433, 26250, 30349, 36413, 6132, 9333, 17971, 12491, 27246, 27364, 28298, 35582, 10750, 35076, 5750, 16386, 24737, 16731, 18046, 26108, 28085, 27593, 43659, 10501, 17686, 42955, 35803, 14970, 7826, 42926, 26113, 10769, 44499, 36773, 8765, 43466, 42615, 43173, 8313, 42650, 35377, 7099, 10614, 27030, 23943]\n",
      "\n",
      "üìå Descri√ß√£o curta:\n",
      "Os casos apresentados giram em torno da contesta√ß√£o do v√≠nculo empregat√≠cio entre trabalhadores e empresas, especialmente quando os trabalhadores s√£o contratados como Microempreendedores Individuais (MEIs) mas alegam que, na pr√°tica, exercem atividades t√≠picas de empregados. Os reclamantes pedem o reconhecimento do v√≠nculo de emprego, a anota√ß√£o na CTPS e o pagamento de verbas rescis√≥rias, horas extras e outras vantagens trabalhistas. As empresas, por sua vez, contestam, alegando que os trabalhadores s√£o aut√¥nomos ou que a rela√ß√£o de trabalho foi formalizada corretamente como MEI.\n",
      "\n",
      "üìò Descri√ß√£o longa:\n",
      "Os casos apresentados compartilham um tema comum relacionado ao reconhecimento do v√≠nculo empregat√≠cio em situa√ß√µes onde os trabalhadores foram contratados como Microempreendedores Individuais (MEIs), mas alegam que, na pr√°tica, exercem atividades t√≠picas de empregados. Os trabalhadores argumentam que, apesar de serem registrados como MEIs, suas atividades apresentam caracter√≠sticas de subordina√ß√£o, pessoalidade, onerosidade e habitualidade, que s√£o os requisitos para configurar um v√≠nculo empregat√≠cio.\n",
      "\n",
      "Os reclamantes pedem a declara√ß√£o de nulidade dos contratos de MEI, reconhecimento do v√≠nculo de emprego, e o pagamento de verbas rescis√≥rias, como saldo de sal√°rio, aviso pr√©vio, f√©rias, FGTS, entre outras. As empresas, por sua vez, contestam, alegando que os trabalhadores prestam servi√ßos de forma aut√¥noma e eventual, e que a contrata√ß√£o como MEI foi leg√≠tima.\n",
      "\n",
      "Essa disputa jur√≠dica envolve a interpreta√ß√£o da legisla√ß√£o trabalhista e a an√°lise das condi√ß√µes de trabalho para determinar se h√° ou n√£o um v√≠nculo empregat√≠cio. A Justi√ßa do Trabalho tem a fun√ß√£o de avaliar as provas apresentadas, como contratos, testemunhas e documentos, para decidir se os trabalhadores t√™m direito √†s verbas e benef√≠cios previstos na legisla√ß√£o trabalhista.\n",
      "\n",
      "‚ùì Quest√µes em discuss√£o:\n",
      "1. **Natureza da Rela√ß√£o Jur√≠dica**: A principal quest√£o debatida foi se a contrata√ß√£o do trabalhador como MEI configurava uma fraude para evitar a caracteriza√ß√£o de um v√≠nculo empregat√≠cio. Isso envolveu a an√°lise de elementos como subordina√ß√£o, pessoalidade e n√£o eventualidade para determinar se havia uma rela√ß√£o de emprego.\n",
      "\n",
      "2. **Verbais Rescis√≥rias**: Discutiu-se se a empresa deveria pagar verbas rescis√≥rias, incluindo aviso-pr√©vio, f√©rias proporcionais, 13¬∫ sal√°rio, FGTS e multa do artigo 477 da CLT. A an√°lise focou na exist√™ncia de um v√≠nculo empregat√≠cio e na correta aplica√ß√£o das normas trabalhistas.\n",
      "\n",
      "3. **Jornada de Trabalho**: Foi debatido se a jornada de trabalho era controlada pela empresa, o que √© um indicativo de rela√ß√£o de emprego. A presen√ßa de controle de jornada e a exist√™ncia de horas extras foram pontos cruciais para a decis√£o.\n",
      "\n",
      "4. **Adicional de Periculosidade e Danos Morais**: Discutiu-se a exist√™ncia de adicional de periculosidade e a possibilidade de danos morais por pejotiza√ß√£o. A an√°lise incluiu a exposi√ß√£o do trabalhador a riscos e a pr√°tica de fraude na contrata√ß√£o.\n",
      "\n",
      "5. **Legitimidade Passiva e Compet√™ncia da Justi√ßa do Trabalho**: Foi questionada a legitimidade passiva das empresas no processo e a compet√™ncia da Justi√ßa do Trabalho para julgar o caso. A an√°lise incluiu a verifica√ß√£o de documentos e a presen√ßa de pressupostos processuais e processuais.\n",
      "\n",
      "Essas quest√µes s√£o centrais em muitos processos trabalhistas envolvendo a contrata√ß√£o de MEIs e a poss√≠vel fraude para evitar a caracteriza√ß√£o de v√≠nculo empregat√≠cio.\n",
      "\n",
      "üí° Solu√ß√µes propostas:\n",
      "Os tribunais t√™m abordado casos de contrata√ß√£o fraudulenta como MEI, reconhecendo frequentemente a exist√™ncia de v√≠nculo empregat√≠cio. Em v√°rias decis√µes, empresas foram condenadas a pagar verbas rescis√≥rias, incluindo saldo de sal√°rio, aviso pr√©vio, f√©rias, FGTS e horas extras. A pejotiza√ß√£o foi frequentemente considerada uma tentativa de burlar a legisla√ß√£o trabalhista. O tribunal tamb√©m analisou a autonomia dos trabalhadores, rejeitando pedidos de v√≠nculo empregat√≠cio quando comprovada a presta√ß√£o de servi√ßos aut√¥nomos. Em casos de fraude, a justi√ßa trabalhista condenou empresas a retificar carteiras de trabalho e pagar multas. A compet√™ncia da Justi√ßa do Trabalho foi questionada em alguns casos, com decis√µes variando sobre a transfer√™ncia para a Justi√ßa Estadual. A confiss√£o ficta e a aus√™ncia de provas robustas foram fatores decisivos em v√°rias senten√ßas, resultando na improced√™ncia de pedidos de verbas trabalhistas.\n",
      "\n",
      "‚öñÔ∏è Teses jur√≠dicas:\n",
      "As teses jur√≠dicas comuns nesses processos giram em torno da validade da contrata√ß√£o de trabalhadores como MEI (Microempreendedor Individual) para mascarar v√≠nculos empregat√≠cios. A fraude √© amplamente considerada nula, e a subordina√ß√£o, pessoalidade e n√£o eventualidade s√£o crit√©rios centrais para reconhecer o v√≠nculo empregat√≠cio. A Justi√ßa do Trabalho pode desconsiderar a forma jur√≠dica adotada e reconhecer a rela√ß√£o de emprego se houver prova robusta dos requisitos legais. A falta de registro na CTPS e a aus√™ncia de controle de jornada tamb√©m s√£o fatores que podem levar ao reconhecimento do v√≠nculo empregat√≠cio. A responsabilidade solid√°ria entre empresas de um grupo econ√¥mico e a aplica√ß√£o de normas coletivas s√£o outras teses relevantes.\n"
     ]
    }
   ],
   "source": [
    "gerar_e_salvar_detalhes_cluster(\"pixtral-12b\", get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2defb42-9537-43a8-b62d-7426445503b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (processos_judiciais)",
   "language": "python",
   "name": "processos_judiciais"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
